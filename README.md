# Effect-of-Tokenization-on-downstream-tasks-with-multinigual-Bert
In Task 1,2,3,4 we analysis highly tokenized words by plotting Bar graphs.

![Picture1](https://user-images.githubusercontent.com/51284717/163800389-1e938e9b-8405-4982-be44-06a685cf3f37.png)
![Picture2](https://user-images.githubusercontent.com/51284717/163800423-46c0f3cd-6974-47d1-aab0-5b0184bad071.png)


![Picture3](https://user-images.githubusercontent.com/51284717/163800445-77ce4af7-fa86-4854-8dc0-b4fe6dd93199.png)
![Picture3](https://user-images.githubusercontent.com/51284717/163800466-cb7e6f01-bd0f-442b-a50c-236da4d6d544.png)
Like this plotted various other graphs






Now we filtered Those words(token with max lenghth/length of the word)<0.75
Translate those words with the help of Microsoft Azure Translator into English.
replaced translated word in original dataset.
Compare Bert Classification Model performance on both original and updated dataset.

![image](https://user-images.githubusercontent.com/51284717/163800585-c44e3dc6-0c6a-4bc0-be01-6d22d04b2f5b.png)



Dataset link-https://indicnlp.ai4bharat.org/indic-glue/
